
@inproceedings{yu_filling_2024,
	title = {Filling the gaps: {Data} {Imputation} {Methods} for {Drug} {Discovery}},
	publisher = {UK QSAR and Cheminformatics Group},
	author = {Yu, Jiahao and Marcus, David},
	month = apr,
	year = {2024},
  pdf = {},
  abstract = {},
  selected = {true},
}

@inproceedings{liu_minimizing_2024,
  abbr = {ICML},
	title = {Minimizing \$f\$-{Divergences} by {Interpolating} {Velocity} {Fields}},
	booktitle = {Proceedings of the 41st {International} {Conference} on {Machine} {Learning}},
	author = {Liu, Song and Yu, Jiahao and Simons, Jack and Yi, Mingxuan and Beaumont, Mark},
	year = {2024},
  month = jul,
	pdf = {},
  abstract = {Many machine learning problems can be formulated as approximating a target distribution using a particle distribution by minimizing a statistical discrepancy. Wasserstein Gradient Flow can be employed to move particles along a path that minimizes the f-divergence between the \textit{target} and \textit{particle} distributions. To perform such movements we need to calculate the corresponding velocity fields which include a density ratio function between these two distributions. While previous works estimated the density ratio function first and then differentiated the estimated ratio, this approach may suffer from overfitting, which leads to a less accurate estimate. Inspired by non-parametric curve fitting, we directly estimate these velocity fields using interpolation. We prove that our method is asymptotically consistent under mild conditions. We validate the effectiveness using novel applications on domain adaptation and missing data imputation.},
  arxiv = {2305.15577}
  selected = {true},
}
